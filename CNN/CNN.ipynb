{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                           #dataloader 可用来从网上下载数据 \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]    \n",
    ")                                                           #转变数据，先变成tensor，再标准化（平均值和标准偏差）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:22<00:00, 2071579.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform,download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)               #shuffle，数据的混合（对排序的数据应用）\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef imshow(img):\\n    img = img/2 +0.5 #unnormalize\\n    npimg= img.numpy()\\n    plt.show(np.transpose(npimg,(1,2,0)))\\n    plt.show()\\n\\n#get some random training images\\ndataiter = iter(train_loader)\\nimages, labels = dataiter.next()\\n\\n\\n#show images\\nimshow(torchvision.utils.make_grid(images))\\n\\n#for testing\\nconv1 = nn.Conv2d(3,6,5)\\npool = nn.MaxPool2d(2,2)\\nconv2 = nn.Conv2d(6,16,5)\\nprint(images.shape)\\nx = conv1(images)\\nprint(x.shape)\\nx = pool(x)\\nprint(x.shape)\\nx = conv2(x)\\nx = pool(x)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
    "'''\n",
    "def imshow(img):\n",
    "    img = img/2 +0.5 #unnormalize\n",
    "    npimg= img.numpy()\n",
    "    plt.show(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "#get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "#show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "#for testing\n",
    "conv1 = nn.Conv2d(3,6,5)            #3为个input的channel(颜色RGB), 6为输出的尺寸, 5为filter的大小kernel\n",
    "pool = nn.MaxPool2d(2,2)            #数据的综合,用pool去使图片减少一半\n",
    "conv2 = nn.Conv2d(6,16,5)           \n",
    "print(images.shape)                 #4sample,3(RGB),32(大小),32(大小32*32)\n",
    "x = conv1(images)\n",
    "print(x.shape)                      #4,6,28,28, 32-5+1=28,详情间下一个code\n",
    "x = pool(x)                         \n",
    "print(x.shape)                      #4,6,14,14\n",
    "x = conv2(x)                        #4,6,10,10\n",
    "x = pool(x)                         ##4,6,5,5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_size : (W(像素点 of image,32*32) - F(5*5,filter) +2P（两边都有)/S(扫描间隔大小) +1 width,filtersize,padding,stride\n",
    "#5*5 input, 3*3 f, p=0,stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement cover net, 有三组，每组颜色均需单独处理。 filter作用于input，依次进行扫描并更新；也可以用pool去综合矩阵信息，将2*2成为1，使矩阵变小\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)           #kernel_size 2 (2*2), stride = 2 (shift)，filter的扫描间隔;\n",
    "        self.conv2 = nn.Conv2d(6,16,5)          #第二层卷积网络\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)       #卷积后接线性，120为隐藏层中神经元个数\n",
    "        \n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)                      #拉成一维进入线性网络\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], step[2000/12500], loss: 0.7676\n",
      "Epoch [1/4], step[4000/12500], loss: 1.0347\n",
      "Epoch [1/4], step[6000/12500], loss: 0.2675\n",
      "Epoch [1/4], step[8000/12500], loss: 1.7167\n",
      "Epoch [1/4], step[10000/12500], loss: 0.9280\n",
      "Epoch [1/4], step[12000/12500], loss: 0.2798\n",
      "Epoch [2/4], step[2000/12500], loss: 2.1132\n",
      "Epoch [2/4], step[4000/12500], loss: 0.4162\n",
      "Epoch [2/4], step[6000/12500], loss: 1.0520\n",
      "Epoch [2/4], step[8000/12500], loss: 0.6305\n",
      "Epoch [2/4], step[10000/12500], loss: 1.0159\n",
      "Epoch [2/4], step[12000/12500], loss: 0.8332\n",
      "Epoch [3/4], step[2000/12500], loss: 1.7283\n",
      "Epoch [3/4], step[4000/12500], loss: 0.2976\n",
      "Epoch [3/4], step[6000/12500], loss: 0.9014\n",
      "Epoch [3/4], step[8000/12500], loss: 1.4985\n",
      "Epoch [3/4], step[10000/12500], loss: 0.5543\n",
      "Epoch [3/4], step[12000/12500], loss: 1.0079\n",
      "Epoch [4/4], step[2000/12500], loss: 1.9921\n",
      "Epoch [4/4], step[4000/12500], loss: 1.7713\n",
      "Epoch [4/4], step[6000/12500], loss: 0.7793\n",
      "Epoch [4/4], step[8000/12500], loss: 1.1594\n",
      "Epoch [4/4], step[10000/12500], loss: 0.5396\n",
      "Epoch [4/4], step[12000/12500], loss: 1.1074\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 ==0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], step[{i+1}/{n_total_steps}], loss: {loss.item():.4f}')\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 61.35%\n",
      "Accuracy of plane:64.1%\n",
      "Accuracy of car:66.5%\n",
      "Accuracy of bird:53.1%\n",
      "Accuracy of cat:38.5%\n",
      "Accuracy of deer:45.1%\n",
      "Accuracy of dog:51.0%\n",
      "Accuracy of frog:75.4%\n",
      "Accuracy of horse:71.4%\n",
      "Accuracy of ship:73.5%\n",
      "Accuracy of truck:74.9%\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] +=1\n",
    "            n_class_samples[label] +=1\n",
    "            \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc}%')\n",
    "    \n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}:{acc}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIforML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
